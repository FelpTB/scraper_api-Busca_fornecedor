# ğŸ” Busca Fornecedor API

API para construÃ§Ã£o automÃ¡tica de perfis de empresas B2B brasileiras. O sistema busca, extrai e processa informaÃ§Ãµes de sites corporativos para gerar perfis estruturados.

## ğŸ¯ O que a API faz

1. **Busca no Google** - Encontra sites oficiais de empresas usando Serper API
2. **Identifica site oficial** - Usa LLM para analisar resultados e identificar o site correto
3. **Extrai conteÃºdo** - Faz scraping de mÃºltiplas pÃ¡ginas do site
4. **Gera perfil estruturado** - Processa conteÃºdo com LLM para extrair informaÃ§Ãµes estruturadas

## ğŸ“Š MÃ©tricas de Performance

| MÃ©trica | Valor |
|---------|-------|
| Throughput | ~155 empresas/min |
| Taxa de Sucesso | ~80% |
| Tempo MÃ©dio Total | ~70s por empresa |
| PÃ¡ginas por Site | atÃ© 100 subpÃ¡ginas |

---

## ğŸ“ Estrutura do Projeto

```
busca_fornecedo_crawl/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py                    # Entry point FastAPI
â”‚   â”œâ”€â”€ api/v2/                    # Endpoints da API
â”‚   â”‚   â”œâ”€â”€ serper.py              # POST /v2/serper
â”‚   â”‚   â”œâ”€â”€ encontrar_site.py      # POST /v2/encontrar_site
â”‚   â”‚   â”œâ”€â”€ scrape.py              # POST /v2/scrape
â”‚   â”‚   â””â”€â”€ montagem_perfil.py     # POST /v2/montagem_perfil
â”‚   â”œâ”€â”€ configs/                   # ConfiguraÃ§Ãµes JSON
â”‚   â”‚   â”œâ”€â”€ llm_providers.json     # Providers LLM
â”‚   â”‚   â”œâ”€â”€ llm_limits.json        # Limites de tokens
â”‚   â”‚   â”œâ”€â”€ discovery/             # Config discovery
â”‚   â”‚   â”œâ”€â”€ scraper/               # Config scraper
â”‚   â”‚   â””â”€â”€ profile/               # Config profile
â”‚   â”œâ”€â”€ core/                      # MÃ³dulos core
â”‚   â”‚   â”œâ”€â”€ config.py              # VariÃ¡veis de ambiente
â”‚   â”‚   â”œâ”€â”€ database.py            # ConexÃ£o PostgreSQL
â”‚   â”‚   â”œâ”€â”€ chunking/              # MÃ³dulo de chunking v4
â”‚   â”‚   â”œâ”€â”€ token_utils.py         # Contagem de tokens
â”‚   â”‚   â””â”€â”€ vllm_client.py         # Cliente vLLM/RunPod
â”‚   â”œâ”€â”€ schemas/                   # Schemas Pydantic
â”‚   â”‚   â””â”€â”€ v2/                    # Schemas dos endpoints v2
â”‚   â””â”€â”€ services/                  # LÃ³gica de negÃ³cio
â”‚       â”œâ”€â”€ agents/                # Agentes LLM
â”‚       â”œâ”€â”€ discovery/             # ServiÃ§o de discovery
â”‚       â”œâ”€â”€ discovery_manager/     # Rate limiting Serper
â”‚       â”œâ”€â”€ scraper/               # Scraper de sites
â”‚       â”œâ”€â”€ scraper_manager/       # Circuit breaker, proxies
â”‚       â”œâ”€â”€ llm_manager/           # Gerenciamento LLM
â”‚       â”œâ”€â”€ profile_builder/       # ConstruÃ§Ã£o de perfis
â”‚       â””â”€â”€ database_service.py    # OperaÃ§Ãµes de banco
â”œâ”€â”€ migrations/                    # Scripts SQL
â”œâ”€â”€ Dockerfile                     # Build Docker
â”œâ”€â”€ Procfile                       # Config Railway
â””â”€â”€ requirements.txt               # DependÃªncias
```

---

## ğŸš€ Endpoints da API v2

A API possui 4 endpoints que devem ser chamados em sequÃªncia:

### 1ï¸âƒ£ POST `/v2/serper` - Busca no Google

Busca informaÃ§Ãµes da empresa no Google via Serper API.

**Request:**
```json
{
  "cnpj_basico": "12345678",
  "razao_social": "EMPRESA EXEMPLO LTDA",
  "nome_fantasia": "Empresa Exemplo",
  "municipio": "SÃ£o Paulo"
}
```

**Response:**
```json
{
  "success": true,
  "serper_id": 123,
  "results_count": 10,
  "query_used": "Empresa Exemplo SÃ£o Paulo site oficial"
}
```

**Dados salvos:** Tabela `serper_results`

---

### 2ï¸âƒ£ POST `/v2/encontrar_site` - Identificar Site Oficial

Usa LLM para analisar os resultados do Serper e identificar o site oficial.

**Request:**
```json
{
  "cnpj_basico": "12345678"
}
```

**Response:**
```json
{
  "success": true,
  "discovery_id": 456,
  "website_url": "https://www.empresa.com.br",
  "discovery_status": "found",
  "confidence_score": 0.95
}
```

**Status possÃ­veis:**
- `found` - Site encontrado com sucesso
- `not_found` - Site nÃ£o encontrado
- `error` - Erro no processamento

**Dados salvos:** Tabela `website_discovery`

---

### 3ï¸âƒ£ POST `/v2/scrape` - Extrair ConteÃºdo do Site

Faz scraping do site e salva conteÃºdo em chunks.

**Request:**
```json
{
  "cnpj_basico": "12345678",
  "website_url": "https://www.empresa.com.br"
}
```

**Response:**
```json
{
  "success": true,
  "chunks_saved": 15,
  "total_tokens": 125000,
  "pages_scraped": 8,
  "processing_time_ms": 3450.5
}
```

**Dados salvos:** Tabela `scraped_chunks`

---

### 4ï¸âƒ£ POST `/v2/montagem_perfil` - Gerar Perfil Estruturado

Processa chunks com LLM para extrair perfil estruturado da empresa.

**Request:**
```json
{
  "cnpj_basico": "12345678"
}
```

**Response:**
```json
{
  "success": true,
  "company_id": 789,
  "profile_status": "success",
  "chunks_processed": 15,
  "processing_time_ms": 5432.1
}
```

**Status possÃ­veis:**
- `success` - Todos os chunks processados
- `partial` - Alguns chunks processados
- `error` - Nenhum chunk processado

**Dados salvos:** Tabela `company_profile`

---

## ğŸ”— IntegraÃ§Ã£o com n8n

### ConfiguraÃ§Ã£o do HTTP Request Node

Para cada endpoint, configure um nÃ³ **HTTP Request** no n8n:

#### ConfiguraÃ§Ãµes Comuns

| Campo | Valor |
|-------|-------|
| Method | POST |
| URL | `https://sua-api.railway.app/v2/{endpoint}` |
| Authentication | Header Auth |
| Header Name | `X-API-Key` |
| Header Value | `sua-api-key` |
| Body Content Type | JSON |

### Fluxo Completo no n8n

```
[Trigger] â†’ [1. Serper] â†’ [2. Encontrar Site] â†’ [3. Scrape] â†’ [4. Montagem Perfil] â†’ [Resultado]
```

### Exemplo: NÃ³ 1 - Serper

**HTTP Request Node:**
```
URL: https://sua-api.railway.app/v2/serper
Method: POST
Headers:
  - X-API-Key: sua-api-key
  - Content-Type: application/json
Body:
{
  "cnpj_basico": "{{ $json.cnpj_basico }}",
  "razao_social": "{{ $json.razao_social }}",
  "nome_fantasia": "{{ $json.nome_fantasia }}",
  "municipio": "{{ $json.municipio }}"
}
```

### Exemplo: NÃ³ 2 - Encontrar Site

**HTTP Request Node:**
```
URL: https://sua-api.railway.app/v2/encontrar_site
Method: POST
Headers:
  - X-API-Key: sua-api-key
  - Content-Type: application/json
Body:
{
  "cnpj_basico": "{{ $json.cnpj_basico }}"
}
```

### Exemplo: NÃ³ 3 - Scrape

**HTTP Request Node:**
```
URL: https://sua-api.railway.app/v2/scrape
Method: POST
Headers:
  - X-API-Key: sua-api-key
  - Content-Type: application/json
Body:
{
  "cnpj_basico": "{{ $json.cnpj_basico }}",
  "website_url": "{{ $node['Encontrar Site'].json.website_url }}"
}
```

**âš ï¸ Importante:** SÃ³ chame o scrape se `discovery_status === "found"`

### Exemplo: NÃ³ 4 - Montagem Perfil

**HTTP Request Node:**
```
URL: https://sua-api.railway.app/v2/montagem_perfil
Method: POST
Headers:
  - X-API-Key: sua-api-key
  - Content-Type: application/json
Body:
{
  "cnpj_basico": "{{ $json.cnpj_basico }}"
}
```

### Fluxo com Condicionais

```
[Serper] 
    â†“
[Encontrar Site] 
    â†“
[IF: discovery_status == "found"]
    â”œâ”€â”€ true â†’ [Scrape] â†’ [Montagem Perfil] â†’ [Sucesso]
    â””â”€â”€ false â†’ [Log: Site nÃ£o encontrado]
```

---

## ğŸ—„ï¸ Banco de Dados

### Tabelas

| Tabela | DescriÃ§Ã£o | Chave |
|--------|-----------|-------|
| `serper_results` | Resultados da busca Google | `cnpj_basico` |
| `website_discovery` | Site oficial descoberto | `cnpj_basico` |
| `scraped_chunks` | Chunks de conteÃºdo extraÃ­do | `cnpj_basico` |
| `company_profile` | Perfil estruturado final | `cnpj` |

### Campos da Tabela `company_profile`

| Campo | Tipo | DescriÃ§Ã£o |
|-------|------|-----------|
| `id` | BIGSERIAL | ID Ãºnico |
| `cnpj` | TEXT | CNPJ completo |
| `company_name` | TEXT | Nome da empresa |
| `industry` | TEXT | Setor de atuaÃ§Ã£o |
| `business_model` | TEXT | Modelo de negÃ³cio |
| `target_audience` | TEXT | PÃºblico-alvo |
| `geographic_coverage` | TEXT | Cobertura geogrÃ¡fica |
| `website_url` | TEXT | URL do site |
| `profile_json` | JSONB | Perfil completo em JSON |
| `created_at` | TIMESTAMPTZ | Data de criaÃ§Ã£o |

### Consultar Perfil Final

```sql
SELECT 
  company_name,
  industry,
  business_model,
  target_audience,
  website_url,
  profile_json
FROM company_profile
WHERE cnpj LIKE '12345678%';
```

---

## âš™ï¸ ConfiguraÃ§Ã£o

### VariÃ¡veis de Ambiente

| VariÃ¡vel | DescriÃ§Ã£o | ObrigatÃ³rio |
|----------|-----------|-------------|
| `API_KEY` | Chave de autenticaÃ§Ã£o da API | âœ… |
| `SERPER_API_KEY` | API key do Serper.dev | âœ… |
| `GEMINI_API_KEY` | API key do Google Gemini | âœ… |
| `OPENAI_API_KEY` | API key da OpenAI | Fallback |
| `DATABASE_URL` | URL de conexÃ£o PostgreSQL | âœ… |
| `RUNPOD_API_KEY` | API key do RunPod (vLLM) | Opcional |
| `WEBSHARE_API_KEY` | API key do WebShare (proxies) | Opcional |

### Deploy no Railway

1. Conecte o repositÃ³rio ao Railway
2. Configure as variÃ¡veis de ambiente
3. O Procfile jÃ¡ estÃ¡ configurado:
   ```
   web: hypercorn app.main:app --bind 0.0.0.0:$PORT
   ```

---

## ğŸ”§ Tecnologias

| Componente | Tecnologia |
|------------|------------|
| Framework | FastAPI |
| HTTP Client | curl_cffi (sem browser) |
| LLM PrimÃ¡rio | Google Gemini |
| LLM Fallback | OpenAI GPT-4 |
| LLM Self-hosted | vLLM via RunPod |
| Busca | Serper.dev (Google) |
| Banco de Dados | PostgreSQL (Supabase) |
| Proxies | WebShare (rotating) |
| Deploy | Railway |

---

## ğŸ“‹ Fluxo de Dados

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        FLUXO COMPLETO                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  [Input: CNPJ + Dados]                                         â”‚
â”‚         â”‚                                                       â”‚
â”‚         â–¼                                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    Salva em                                   â”‚
â”‚  â”‚ 1. Serper   â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º serper_results                â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                               â”‚
â”‚         â”‚                                                       â”‚
â”‚         â–¼                                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    Salva em                              â”‚
â”‚  â”‚ 2. Encontrar Siteâ”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º website_discovery        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                          â”‚
â”‚         â”‚                                                       â”‚
â”‚         â–¼ (se found)                                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    Salva em                                   â”‚
â”‚  â”‚ 3. Scrape   â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º scraped_chunks                â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                               â”‚
â”‚         â”‚                                                       â”‚
â”‚         â–¼                                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    Salva em                              â”‚
â”‚  â”‚ 4. Montagem Perfilâ”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º company_profile         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                          â”‚
â”‚         â”‚                                                       â”‚
â”‚         â–¼                                                       â”‚
â”‚  [Output: Perfil Estruturado]                                  â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ› Tratamento de Erros

| CÃ³digo | DescriÃ§Ã£o | AÃ§Ã£o Recomendada |
|--------|-----------|------------------|
| 200 | Sucesso | Continuar fluxo |
| 400 | Request invÃ¡lido | Verificar campos obrigatÃ³rios |
| 401 | NÃ£o autorizado | Verificar API Key |
| 500 | Erro interno | Verificar logs, retry apÃ³s 30s |

### Retry no n8n

Configure o nÃ³ HTTP Request com:
- **Continue On Fail**: true
- **Retry On Fail**: true
- **Max Tries**: 3
- **Wait Between Tries**: 30000 (30s)

---

## ğŸ“œ Changelog

### v5.0 (Atual)
- âœ… Endpoints v2 separados (serper, encontrar_site, scrape, montagem_perfil)
- âœ… PersistÃªncia em PostgreSQL (Supabase)
- âœ… Chunking v4 com deduplicaÃ§Ã£o (~94% economia de tokens)
- âœ… Suporte a vLLM via RunPod
- âœ… Phoenix Tracing para observabilidade LLM
- âœ… Estrutura de projeto limpa e otimizada

### v4.0
- âœ… MÃ³dulo de Chunking isolado
- âœ… DeduplicaÃ§Ã£o de linhas repetidas

### v3.0
- âœ… SeparaÃ§Ã£o de managers (scraper, discovery, llm)
- âœ… Circuit Breaker com estados
- âœ… Cache de buscas

---

## ğŸ“„ LicenÃ§a

ProprietÃ¡rio - Uso interno apenas.

---

*DocumentaÃ§Ã£o atualizada em Janeiro 2026*
