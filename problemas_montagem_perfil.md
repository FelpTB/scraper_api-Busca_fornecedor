Abaixo estÃ¡ um **resumo tÃ©cnico e executivo** dos principais problemas de repetiÃ§Ã£o/degeneraÃ§Ã£o que vocÃªs enfrentam, das **causas estruturais**, da **stack jÃ¡ existente**, das **soluÃ§Ãµes aplicadas** e das **limitaÃ§Ãµes ainda presentes**, com exemplos concretos do que ocorre em produÃ§Ã£o.

---

## 1) Natureza do problema

O problema central nÃ£o Ã© â€œJSON invÃ¡lidoâ€.
Ã‰ **degeneraÃ§Ã£o semÃ¢ntica dentro de campos vÃ¡lidos**, principalmente em **listas longas**.

CaracterÃ­sticas principais:

* O JSON continua vÃ¡lido (graÃ§as ao XGrammar).
* O modelo entra em **loop interno em arrays permitidos**.
* O output cresce sem valor semÃ¢ntico.
* A latÃªncia explode.
* A qualidade cai quando se aplica penalidade forte.

O problema ocorre **mesmo com constrained decoding**, porque:

* O schema controla *forma*, nÃ£o controla *dinÃ¢mica de parada*.
* `uniqueItems` e `maxItems` **nÃ£o sÃ£o aplicados como restriÃ§Ãµes duras durante a geraÃ§Ã£o** (apenas na validaÃ§Ã£o).

---

## 2) Onde o problema nasce (zonas de alto risco)

Campos crÃ­ticos no schema:

### 2.1 ProductCategory.items

**Principal fonte de loops**

Exemplo real tÃ­pico:

```json
"items": [
  "RCA",
  "Conector RCA",
  "RCA macho",
  "RCA fÃªmea",
  "Conector RCA macho",
  "RCA plug",
  "RCA adaptador",
  "RCA adaptador macho",
  ...
]
```

Sintomas:

* VariaÃ§Ãµes mÃ­nimas do mesmo token.
* Crescimento quase infinito atÃ© bater `max_tokens`.
* JSON vÃ¡lido, mas semanticamente inÃºtil.

---

### 2.2 offerings.products

Quando o site tem catÃ¡logos genÃ©ricos ou listas tÃ©cnicas:

```json
"products": [
  "P2",
  "P10",
  "XLR",
  "Cabo P2",
  "Cabo P2 estÃ©reo",
  "Cabo P2 3.5mm",
  ...
]
```

O modelo tenta â€œexaurir o espaÃ§oâ€ permitido.

---

### 2.3 reputation.client_list / partnerships

Quando hÃ¡ listas de logotipos ou nomes em grids:

```json
"client_list": [
  "Petrobras",
  "Petrobras RJ",
  "Petrobras SP",
  "Grupo Petrobras",
  "Petrobras Brasil",
  ...
]
```

RepetiÃ§Ã£o semÃ¢ntica com pequenas variaÃ§Ãµes.

---

## 3) Por que isso acontece (causas profundas)

### 3.1 EspaÃ§o de saÃ­da excessivo no schema

VocÃªs originalmente tinham:

* `products: maxItems 200`
* `ProductCategory.items: maxItems 200`
* `client_list: 200`
* `partnerships: 100`

Isso cria uma situaÃ§Ã£o estruturalmente perigosa:

> O modelo **nÃ£o sabe quando parar** e o schema permite continuar.

Mesmo com XGrammar:

* Ele sÃ³ garante que o token emitido Ã© vÃ¡lido no campo.
* Ele **nÃ£o impÃµe parada global** baseada em significado.

---

### 3.2 Penalidades anti-loop trabalham contra extraÃ§Ã£o

Quando vocÃªs aumentaram:

* `presence_penalty`
* `frequency_penalty`

Efeitos observados:

1. O modelo evita repetir â†’ comeÃ§a a:

   * pular campos legÃ­timos
   * colapsar para `[]`
   * empobrecer descriÃ§Ãµes

2. A qualidade geral do perfil despenca:

   * identity incompleta
   * offerings sub-preenchido
   * reputation vazia

Ou seja:

* Loop â†“
* Qualidade â†“â†“â†“

---

### 3.3 Prompt sobrecarregado com schema completo

VocÃªs colavam:

* Schema no `response_format`
* **E tambÃ©m no User Prompt**

ConsequÃªncias:

* A atenÃ§Ã£o do modelo se dispersa.
* Menos foco no texto scraped.
* Maior chance de degeneraÃ§Ã£o em listas.

---

### 3.4 max_tokens global nÃ£o resolve runaway local

O runaway nasce em **1 campo especÃ­fico**.
Reduzir `max_tokens` global:

* corta identity / contact / classification
* mas o loop ainda tenta nascer
* piora recall geral

---

## 4) Stack atual (nÃ­vel muito alto de maturidade)

VocÃªs jÃ¡ possuem uma das stacks mais completas possÃ­veis para esse problema:

### 4.1 Constrained decoding

* **SGLang + XGrammar**
* `response_format = json_schema`
* `strict = True`

Resultado:

* JSON sempre vÃ¡lido
* Estrutura garantida
* Parsing praticamente 100% confiÃ¡vel

---

### 4.2 Prompt engineering avanÃ§ado

Elementos presentes:

* EvidÃªncia dura (anti-alucinaÃ§Ã£o)
* Roteamento fechado por campo
* Regras explÃ­citas serviÃ§o â‰  produto
* Anti-vazio em objetos
* Micro-shots direcionados
* Anti-expansÃ£o de termos genÃ©ricos

Esse nÃ­vel de disciplina Ã© **acima da mÃ©dia de produÃ§Ã£o**.

---

### 4.3 ProteÃ§Ãµes runtime

* Adaptive `max_tokens` por tamanho de input

* Loop detector heurÃ­stico:

  * n-gram repetido
  * chunk repetido
  * runaway sem fechar JSON

* Retry seletivo com parÃ¢metros ajustados

* PÃ³s-process determinÃ­stico:

  * deduplicaÃ§Ã£o
  * filtro anti-template
  * hard caps finais

Essa arquitetura jÃ¡ Ã© **industrial-grade**.

---

## 5) LimitaÃ§Ã£o fundamental que permaneceu

Mesmo com tudo isso, restou um ponto estrutural:

> **O modelo ainda decide sozinho quando parar listas.**

Nem:

* XGrammar
* uniqueItems
* maxItems
* penalidades

garantem parada **semÃ¢ntica correta**.

O sistema sÃ³ impede:

* JSON invÃ¡lido
* quebra estrutural

Ele **nÃ£o impede degeneraÃ§Ã£o interna vÃ¡lida**.

---

## 6) SoluÃ§Ãµes aplicadas na v9.1 (e por que funcionam)

### 6.1 ReduÃ§Ã£o agressiva de espaÃ§o de degeneraÃ§Ã£o (schema-level)

MudanÃ§a crÃ­tica:

* `products`: 200 â†’ **60**
* `product_categories`: 80 â†’ **40**
* `ProductCategory.items`: 200 â†’ **80**
* `client_list`: 200 â†’ **80**
* `partnerships`: 100 â†’ **50**

Efeito direto:

* Menos espaÃ§o para runaway
* Menos tokens gerados
* Menos latÃªncia
* Loop muito mais raro

Essa Ã© a **mudanÃ§a de maior impacto real**.

---

### 6.2 RemoÃ§Ã£o do schema do User Prompt

Antes:

* schema no prompt
* schema no response_format

Agora:

* schema **somente** no XGrammar

Efeitos:

* menos ruÃ­do cognitivo
* melhor foco no conteÃºdo scraped
* melhor qualidade sem aumentar custo

---

### 6.3 Troca de penalidades por controle estrutural

MudanÃ§a:

* `presence_penalty`: 0
* `frequency_penalty`: 0
* (opcional) `repetition_penalty`: leve (â‰ˆ1.08)

Efeito:

* recupera fidelidade textual
* evita sub-preenchimento
* deixa o controle de loop **para o schema + caps**, nÃ£o para criatividade

---

### 6.4 Retry baseado em tamanho, nÃ£o em criatividade

Antes:

* retry subia penalidades â†’ matava qualidade

Agora:

* retry reduz `max_tokens`
* sobe levemente `repetition_penalty`
* mantÃ©m criatividade controlada

Resultado:

* recuperaÃ§Ã£o sem colapsar perfil

---

## 7) Exemplos tÃ­picos de falhas observadas

### Caso A â€” DegeneraÃ§Ã£o em ProductCategory.items

Input:

> â€œConectores disponÃ­veis: RCA, P2, P10, XLRâ€

Output ruim (antes v9.1):

```json
"items": [
  "RCA",
  "Conector RCA",
  "RCA macho",
  "RCA fÃªmea",
  "RCA plug",
  "RCA adaptador",
  "RCA adaptador macho",
  "RCA adaptador fÃªmea",
  ...
]
```

Efeito:

* 200+ itens
* latÃªncia alta
* pÃ³s-process corta brutalmente
* semÃ¢ntica pobre

---

### Caso B â€” Sub-preenchimento apÃ³s penalidades

ApÃ³s subir `frequency_penalty`:

```json
"services": [],
"products": [],
"product_categories": [],
"client_list": []
```

Mesmo quando havia evidÃªncia clara.

Efeito:

* loop â†“
* qualidade â†“â†“â†“
* recall quase zero em campos crÃ­ticos

---

### Caso C â€” VariaÃ§Ã£o mÃ­nima em clientes

Input:

> â€œClientes: Petrobras, Vale, Ambevâ€

Output ruim:

```json
"client_list": [
  "Petrobras",
  "Petrobras RJ",
  "Grupo Petrobras",
  "Petrobras Brasil",
  "Vale",
  "Vale S.A.",
  "Vale MineraÃ§Ã£o",
  ...
]
```

Mesmo nome expandido artificialmente.

---

## 8) ConclusÃ£o tÃ©cnica

O problema **nÃ£o era**:

* JSON invÃ¡lido
* parsing
* prompt fraco
* ausÃªncia de constrained decoding

O problema era:

### ğŸ”´ Um desequilÃ­brio estrutural entre:

* espaÃ§o de saÃ­da enorme
* listas abertas
* ausÃªncia de parada semÃ¢ntica nativa nos LLMs

e

* necessidade de extraÃ§Ã£o precisa
* latÃªncia previsÃ­vel
* zero alucinaÃ§Ã£o

---

## 9) Estado atual (v9.1)

Com as mudanÃ§as:

* Loop rate â†“ drasticamente
* LatÃªncia p95/p99 â†“
* Qualidade recuperada
* Menos retries
* JSON sempre vÃ¡lido
* Perfil mais estÃ¡vel e consistente

O sistema agora estÃ¡:

* **constrained por design** (schema + caps)
* **guiado por polÃ­tica** (prompt)
* **protegido por runtime** (detector + retry + pÃ³s-process)

Esse Ã© exatamente o padrÃ£o usado em pipelines industriais de:

* company profiling
* KYC
* enrichment B2B
* data extraction regulada

---

Se vocÃª quiser, no prÃ³ximo passo eu posso:

* transformar isso em um **documento tÃ©cnico oficial** (post-mortem / design doc)
* ou um **â€œproblem statement + solution architectureâ€** para apresentar a outro engenheiro, time ou stakeholder.