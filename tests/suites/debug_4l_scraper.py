import asyncio
import logging
import sys
import os

# Adicionar diret√≥rio raiz ao path
sys.path.append(os.getcwd())

from app.services.scraper.http_client import cffi_scrape_safe
# from app.services.scraper.html_parser import extract_links_and_docs # REMOVIDO
from app.services.scraper.link_selector import filter_non_html_links, prioritize_links

# Configurar logging para ver detalhes
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

async def debug_site():
    url = "http://4lmecanizacao.com.br/"
    print(f"\nüîç INICIANDO DIAGN√ìSTICO PARA: {url}")
    print("=" * 60)

    # 1. Teste de Acesso B√°sico (Raw HTML)
    print("\n1Ô∏è‚É£  Tentando baixar HTML da Home...")
    try:
        html, docs, links = await cffi_scrape_safe(url, proxy=None)
        
        if not html:
            print("‚ùå Falha: HTML vazio retornado.")
            return
            
        print(f"‚úÖ Sucesso! HTML baixado: {len(html)} caracteres.")
        print(f"   Links brutos encontrados (parser interno): {len(links)}")
        
        # Mostrar amostra do HTML para ver estrutura de navega√ß√£o
        print("\nüìÑ Amostra do HTML (primeiros 1000 chars):")
        print("-" * 40)
        print(html[:1000])
        print("-" * 40)
        
        # Verificar Frames/IFrames
        if "<frame" in html.lower() or "<iframe" in html.lower():
            print("\n‚ö†Ô∏è  ALERTA: Frames/iFrames detectados no HTML!")
        
    except Exception as e:
        print(f"‚ùå Erro fatal ao baixar: {e}")
        return

    # 2. An√°lise de Links
    print("\n2Ô∏è‚É£  An√°lise Detalhada dos Links Encontrados:")
    print("-" * 60)
    
    if not links:
        print("‚ö†Ô∏è  NENHUM link encontrado no parser padr√£o!")
        print("   -> Causa prov√°vel: Menu em Flash, JS puro ou Image Map.")
    else:
        print("üîó Links Brutos (Top 10):")
        for l in list(links)[:10]:
            print(f"   - {l}")

        # Filtragem
        filtered = filter_non_html_links(links)
        print(f"\n   Links ap√≥s filtro de arquivos (img/css/pdf): {len(filtered)}")
        
        prioritized = prioritize_links(filtered, url)
        print(f"   Links priorizados para visita: {len(prioritized)}")
        
        if prioritized:
            print("\n   Top Links Candidatos:")
            for l in prioritized[:5]:
                print(f"   -> {l}")
        else:
            print("\n‚ö†Ô∏è  Todos os links foram filtrados ou considerados irrelevantes!")

    # 3. Teste de Acessibilidade de um Link Interno (se houver)
    if prioritized:
        test_link = prioritized[0]
        print(f"\n3Ô∏è‚É£  Testando acesso ao primeiro link interno: {test_link}")
        try:
            sub_html, _, _ = await cffi_scrape_safe(test_link, proxy=None)
            if sub_html and len(sub_html) > 100:
                print(f"‚úÖ Sucesso! Subp√°gina acess√≠vel ({len(sub_html)} chars).")
            else:
                print(f"‚ùå Falha: Subp√°gina retornou vazio ou erro.")
        except Exception as e:
            print(f"‚ùå Erro ao acessar subp√°gina: {e}")

if __name__ == "__main__":
    asyncio.run(debug_site())

