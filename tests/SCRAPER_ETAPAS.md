# Mapeamento Completo do Processo de Scraping

## Vis√£o Geral

O processo de scraping √© composto por **8 etapas principais**, cada uma com suas subetapas. Este documento mapeia todas as etapas, m√≥dulos dependentes e pontos de otimiza√ß√£o.

---

## Arquitetura dos M√≥dulos

```
app/services/scraper/
‚îú‚îÄ‚îÄ __init__.py              # Exports e configura√ß√£o
‚îú‚îÄ‚îÄ scraper_service.py       # Orquestrador principal (scrape_url)
‚îú‚îÄ‚îÄ url_prober.py           # Probe de URLs e varia√ß√µes
‚îú‚îÄ‚îÄ site_analyzer.py        # An√°lise de tipo e prote√ß√£o
‚îú‚îÄ‚îÄ protection_detector.py  # Detec√ß√£o de prote√ß√µes
‚îú‚îÄ‚îÄ strategy_selector.py    # Sele√ß√£o de estrat√©gias
‚îú‚îÄ‚îÄ http_client.py          # Cliente HTTP (cffi/curl)
‚îú‚îÄ‚îÄ html_parser.py          # Parser HTML e extra√ß√£o
‚îú‚îÄ‚îÄ link_selector.py        # Sele√ß√£o de links com LLM
‚îú‚îÄ‚îÄ circuit_breaker.py      # Circuit breaker por dom√≠nio
‚îú‚îÄ‚îÄ constants.py            # Configura√ß√µes e constantes
‚îî‚îÄ‚îÄ models.py               # Modelos de dados
```

---

## ETAPA 1: Consulta de Conhecimento Pr√©vio

**Objetivo:** Verificar se j√° temos conhecimento sobre o site.

**M√≥dulos:** `app/services/learning/site_knowledge.py`, `app/services/learning/adaptive_config.py`

### Subetapas:
| # | Subetapa | Descri√ß√£o | Tempo T√≠pico |
|---|----------|-----------|--------------|
| 1.1 | Consultar site_knowledge | Busca perfil existente do site | ~0.1ms |
| 1.2 | Usar aprendizado global | Se site novo, usa padr√µes aprendidos | ~0.01ms |

### Dados Coletados:
- `known_strategy`: Estrat√©gia que funcionou anteriormente
- `known_protection`: Tipo de prote√ß√£o conhecida
- `total_attempts`: N√∫mero de tentativas anteriores

---

## ETAPA 2: Probe URL

**Objetivo:** Encontrar a melhor varia√ß√£o de URL acess√≠vel.

**M√≥dulo:** `app/services/scraper/url_prober.py`

### Subetapas:
| # | Subetapa | Descri√ß√£o | Tempo T√≠pico |
|---|----------|-----------|--------------|
| 2.1 | Verificar cache | Verifica se URL j√° foi validada | ~0.01ms |
| 2.2 | Testar URL original | Testa a URL fornecida primeiro | ~500-2000ms |
| 2.3 | Gerar varia√ß√µes | Gera http/https, www/non-www | ~0.1ms |
| 2.4 | Testar varia√ß√µes | Testa varia√ß√µes em paralelo | ~1000-5000ms |
| 2.5 | Selecionar melhor | Escolhe a mais r√°pida com status OK | ~0.1ms |

### Configura√ß√µes:
- `timeout`: 10s por varia√ß√£o
- `max_concurrent`: 500 conex√µes simult√¢neas

### Pontos de Otimiza√ß√£o:
- ‚ö° Cache agressivo de URLs validadas
- ‚ö° Paraleliza√ß√£o das varia√ß√µes
- ‚ö° Usar HEAD request ao inv√©s de GET

---

## ETAPA 3: An√°lise do Site

**Objetivo:** Determinar tipo de site e prote√ß√µes.

**M√≥dulos:** `site_analyzer.py`, `protection_detector.py`

### Subetapas:
| # | Subetapa | Descri√ß√£o | Tempo T√≠pico |
|---|----------|-----------|--------------|
| 3.1 | Probe inicial | GET completo para medir tempo de resposta | ~500-3000ms |
| 3.2 | Detectar prote√ß√£o | Cloudflare, WAF, Captcha, Rate Limit, Bot | ~1ms |
| 3.3 | Detectar tipo site | Static, SPA, Hybrid, Unknown | ~10ms |
| 3.4 | Verificar robots.txt | GET em /robots.txt | ~200-1000ms |
| 3.5 | Selecionar estrat√©gia | Determina melhor abordagem | ~0.1ms |

### Tipos de Site:
- **Static**: Site tradicional HTML
- **SPA**: Single Page Application (React, Vue, Angular)
- **Hybrid**: Parcialmente SPA
- **Unknown**: N√£o determinado

### Tipos de Prote√ß√£o:
- **None**: Sem prote√ß√£o
- **Cloudflare**: Challenge Cloudflare
- **WAF**: Web Application Firewall
- **Captcha**: reCAPTCHA, hCaptcha
- **Rate_limit**: Limita√ß√£o de taxa
- **Bot_detection**: Detec√ß√£o de bot gen√©rica

### Pontos de Otimiza√ß√£o:
- ‚ö° Cache do resultado de an√°lise
- ‚ö° Paralelizar probe + robots.txt
- ‚ö†Ô∏è robots.txt √© opcional - considerar remover

---

## ETAPA 4: Sele√ß√£o de Estrat√©gias

**Objetivo:** Definir ordem de estrat√©gias a tentar.

**M√≥dulo:** `strategy_selector.py`

### Subetapas:
| # | Subetapa | Descri√ß√£o | Tempo T√≠pico |
|---|----------|-----------|--------------|
| 4.1 | Consultar por prote√ß√£o | Lista estrat√©gias para prote√ß√£o detectada | ~0.01ms |
| 4.2 | Consultar por tipo | Lista estrat√©gias para tipo de site | ~0.01ms |
| 4.3 | Priorizar conhecimento | Move estrat√©gia conhecida para topo | ~0.01ms |
| 4.4 | Ordenar estrat√©gias | Ordena por prioridade final | ~0.01ms |

### Estrat√©gias Dispon√≠veis:
| Estrat√©gia | Timeout | Proxy | UA Rotation | Uso |
|------------|---------|-------|-------------|-----|
| **FAST** | 10s | N√£o | N√£o | Sites r√°pidos sem prote√ß√£o |
| **STANDARD** | 15s | Sim | N√£o | Sites normais |
| **ROBUST** | 20s | Sim | Sim | Sites com prote√ß√£o leve |
| **AGGRESSIVE** | 25s | Sim | Sim + Rotation | Sites com prote√ß√£o forte |

---

## ETAPA 5: Scrape da Main Page

**Objetivo:** Obter conte√∫do da p√°gina principal.

**M√≥dulos:** `http_client.py`, `html_parser.py`

### Subetapas:
| # | Subetapa | Descri√ß√£o | Tempo T√≠pico |
|---|----------|-----------|--------------|
| 5.1 | Tentar estrat√©gia | Executa scrape com estrat√©gia atual | ~500-5000ms |
| 5.1.1 | Rota√ß√£o de UA | Seleciona User-Agent se configurado | ~0.01ms |
| 5.1.2 | Obter proxy | Busca proxy do pool se configurado | ~0.1ms |
| 5.1.3 | HTTP Request | curl_cffi ou system curl | ~500-4000ms |
| 5.1.4 | Verificar qualidade | Valida >= 500 chars | ~0.1ms |
| 5.1.5 | Detectar prote√ß√£o | Verifica Cloudflare/WAF no corpo | ~1ms |
| 5.1.6 | Fallback | Tenta pr√≥xima estrat√©gia se falhou | - |
| 5.2 | Parsing HTML | BeautifulSoup extrai texto | ~10-100ms |
| 5.2.1 | Extrair texto | Remove scripts, extrai texto limpo | ~5-50ms |
| 5.2.2 | Extrair docs | Links de PDFs, DOCs | ~1-10ms |
| 5.2.3 | Extrair links | Links internos | ~1-10ms |
| 5.3 | Verificar qualidade | soft 404, Cloudflare challenge | ~1ms |

### M√©todos de HTTP:
1. **curl_cffi**: Imita Chrome, bypass Cloudflare
2. **system_curl**: Fallback usando curl do sistema

### Pontos de Otimiza√ß√£o:
- ‚ö° Usar HEAD para verificar antes de GET
- ‚ö° Streaming para p√°ginas grandes
- ‚ö†Ô∏è Verificar necessidade de todas as estrat√©gias

---

## ETAPA 6: Sele√ß√£o de Links (LLM)

**Objetivo:** Priorizar links mais relevantes para perfil.

**M√≥dulo:** `link_selector.py`

### Subetapas:
| # | Subetapa | Descri√ß√£o | Tempo T√≠pico |
|---|----------|-----------|--------------|
| 6.1 | Filtrar n√£o-HTML | Remove docs, imagens, assets | ~1-5ms |
| 6.2 | Short-circuit | Se <= max_links, retorna todos | ~0.1ms |
| 6.3 | Chamar LLM | GPT/Gemini para priorizar | ~500-3000ms |
| 6.4 | Parsear resposta | Extrai √≠ndices do JSON | ~1ms |
| 6.5 | Fallback heur√≠sticas | Se LLM falhar, usa keywords | ~1ms |

### Keywords de Alta Prioridade:
- sobre, quem-somos, institucional
- produtos, servi√ßos, solu√ß√µes
- clientes, cases, projetos
- contato, equipe

### Keywords de Baixa Prioridade:
- blog, news, login, cart, policy

### Pontos de Otimiza√ß√£o:
- ‚ö° Cache de respostas LLM por padr√£o de site
- ‚ö° Heur√≠sticas mais agressivas para reduzir chamadas LLM
- ‚ö†Ô∏è Considerar remover LLM e usar s√≥ heur√≠sticas

---

## ETAPA 7: Scrape das Subp√°ginas

**Objetivo:** Coletar conte√∫do das p√°ginas selecionadas.

**M√≥dulos:** `http_client.py`, `circuit_breaker.py`

### Subetapas:
| # | Subetapa | Descri√ß√£o | Tempo T√≠pico |
|---|----------|-----------|--------------|
| 7.1 | Dividir em chunks | Agrupa URLs em lotes de 20 | ~0.1ms |
| 7.2 | Processar chunk | Para cada chunk: | - |
| 7.2.1 | Obter proxy | Proxy compartilhado para chunk | ~0.1ms |
| 7.2.2 | Criar sess√£o | Sess√£o curl_cffi compartilhada | ~10ms |
| 7.2.3 | Scrape URLs | Para cada URL no chunk | ~100-2000ms/URL |
| 7.2.4 | Circuit breaker | Pula dom√≠nios com muitas falhas | ~0.1ms |
| 7.2.5 | Normalizar URL | Remove caracteres problem√°ticos | ~0.1ms |
| 7.2.6 | Fallback | system_curl se cffi falhar | - |
| 7.3 | Consolidar | Agrupa todos os resultados | ~0.1ms |

### Configura√ß√µes:
- `chunk_size`: 20 URLs por chunk
- `chunk_semaphore_limit`: 100 chunks paralelos
- `circuit_breaker_threshold`: 5 falhas para abrir

### Pontos de Otimiza√ß√£o:
- ‚ö° **PRINCIPAL GARGALO** - Otimizar paralelismo
- ‚ö° Aumentar chunk_size para sites est√°veis
- ‚ö° Reutilizar sess√µes HTTP entre chunks
- ‚ö° Pipelining de requests

---

## ETAPA 8: Consolida√ß√£o e Aprendizado

**Objetivo:** Agregar resultados e registrar aprendizado.

**M√≥dulos:** `models.py`, `site_knowledge.py`

### Subetapas:
| # | Subetapa | Descri√ß√£o | Tempo T√≠pico |
|---|----------|-----------|--------------|
| 8.1 | Criar ScrapedContent | Objeto com todos os dados | ~0.1ms |
| 8.2 | Calcular m√©tricas | success_rate, visited_urls | ~0.1ms |
| 8.3 | Registrar aprendizado | Atualiza site_knowledge | ~1ms |
| 8.4 | Retornar | Retorna conte√∫do agregado | ~0.1ms |

---

## Fluxo de Dados

```
URL Input
    ‚îÇ
    ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ ETAPA 1: Conhecimento Pr√©vio                                  ‚îÇ
‚îÇ   site_knowledge.get_profile() ‚Üí known_strategy, protection   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
    ‚îÇ
    ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ ETAPA 2: Probe URL                                            ‚îÇ
‚îÇ   url_prober.probe() ‚Üí best_url, response_time                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
    ‚îÇ
    ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ ETAPA 3: An√°lise do Site                                      ‚îÇ
‚îÇ   site_analyzer.analyze() ‚Üí SiteProfile                       ‚îÇ
‚îÇ   (site_type, protection_type, requires_js, best_strategy)    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
    ‚îÇ
    ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ ETAPA 4: Sele√ß√£o de Estrat√©gias                              ‚îÇ
‚îÇ   strategy_selector.select() ‚Üí [strategies ordered]           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
    ‚îÇ
    ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ ETAPA 5: Scrape Main Page                                     ‚îÇ
‚îÇ   _scrape_main_page() ‚Üí ScrapedPage                           ‚îÇ
‚îÇ   (content, links, documents, strategy_used)                  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
    ‚îÇ
    ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ ETAPA 6: Sele√ß√£o de Links                                     ‚îÇ
‚îÇ   select_links_with_llm() ‚Üí [target_subpages]                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
    ‚îÇ
    ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ ETAPA 7: Scrape Subp√°ginas     ‚ö†Ô∏è PRINCIPAL GARGALO           ‚îÇ
‚îÇ   _scrape_subpages_adaptive() ‚Üí [ScrapedPage]                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
    ‚îÇ
    ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ ETAPA 8: Consolida√ß√£o                                         ‚îÇ
‚îÇ   ScrapedContent + site_knowledge.record_success()            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
    ‚îÇ
    ‚ñº
Output: (aggregated_content, document_links, visited_urls)
```

---

## Distribui√ß√£o de Tempo T√≠pica

| Etapa | % do Tempo | Prioridade Otimiza√ß√£o |
|-------|------------|----------------------|
| Subp√°ginas (7) | 70-80% | üî¥ ALTA |
| An√°lise (3) | 10-15% | üü° M√âDIA |
| Main Page (5) | 5-10% | üü° M√âDIA |
| Links LLM (6) | 3-8% | üü° M√âDIA |
| Probe (2) | 2-5% | üü¢ BAIXA |
| Outros (1,4,8) | <1% | üü¢ BAIXA |

---

## Testes Dispon√≠veis

```bash
# Teste detalhado com m√©tricas de cada etapa
python tests/suites/test_scraper_detailed.py [n_urls] [concurrent] [timeout] [max_subpages]

# Analisar relat√≥rio gerado
python tests/suites/analyze_scraper_report.py [report_path]
```

### Exemplos:
```bash
# Teste r√°pido com 10 URLs
python tests/suites/test_scraper_detailed.py 10 5 60 10

# Teste completo com 100 URLs
python tests/suites/test_scraper_detailed.py 100 20 120 30

# Analisar √∫ltimo relat√≥rio
python tests/suites/analyze_scraper_report.py
```

